{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.regularizers import l1, l2\n",
    "from models import Unet_Model, CNN_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "    x_train = np.load(path + \"/x_train.npy\")\n",
    "    x_val = np.load(path + \"/x_val.npy\")\n",
    "    x_test = np.load(path + \"/x_test.npy\")\n",
    "    y_train = np.load(path + \"/y_train.npy\")\n",
    "    y_val = np.load(path + \"/y_val.npy\")\n",
    "    y_test = np.load(path + \"/y_test.npy\")\n",
    "    z_train = np.load(path + \"/z_train.npy\")\n",
    "    z_val = np.load(path + \"/z_val.npy\")\n",
    "    z_test = np.load(path + \"/z_test.npy\")\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test, z_train, z_val, z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "x_train, x_val, x_test, y_train, y_val, y_test, z_train, z_val, z_test = import_data(\"data128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tuning\n",
    "\n",
    "# Regularization\n",
    "regularization = [None, \"l1\", \"l2\"]\n",
    "\n",
    "# Dropout rate\n",
    "drop_rate = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Upsampling\n",
    "up_sample = [False, True]\n",
    "\n",
    "# Batch Normalization\n",
    "batch_norm = [True, False]\n",
    "\n",
    "# Learning Rate\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "best_configuration = dict(\n",
    "    val_loss=float(\"inf\"), \n",
    "    reg=regularization[0], \n",
    "    dr=drop_rate[1], \n",
    "    us=up_sample[0], \n",
    "    bn=batch_norm[1], \n",
    "    lr=learning_rate[1], \n",
    "    epoch_num=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730085053.753911   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.775704   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.775743   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.777705   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.777747   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.777763   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.932386   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730085053.932433   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-28 10:10:53.932443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730085053.932476   48097 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-28 10:10:53.932495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730085059.993893   48258 service.cc:146] XLA service 0x7f1d70042ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730085059.993933   48258 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-28 10:11:00.174354: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-28 10:11:00.937134: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "I0000 00:00:1730085076.976957   48258 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=0.14003829658031464 (reg=None)\n",
      "*** best_configuration updated\n",
      "val_loss=0.768832266330719 (reg=l1)\n",
      "val_loss=0.28613072633743286 (reg=l2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=0.13951614499092102 (dr=0.1)\n",
      "*** best_configuration updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=0.13813170790672302 (dr=0.2)\n",
      "*** best_configuration updated\n",
      "val_loss=0.15285170078277588 (dr=0.3)\n",
      "val_loss=0.16078081727027893 (dr=0.4)\n",
      "val_loss=0.14754758775234222 (dr=0.5)\n",
      "val_loss=0.15158602595329285 (us=False)\n",
      "val_loss=0.13946713507175446 (us=True)\n",
      "val_loss=0.182280033826828 (bn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=0.13420577347278595 (bn=False)\n",
      "*** best_configuration updated\n"
     ]
    }
   ],
   "source": [
    "with open(\"unet_tuning_output.txt\", \"a\") as f:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Run at {current_time}\\n\", file=f)\n",
    "\n",
    "    for reg in regularization:\n",
    "        UNet_model = Unet_Model(input_shape=(128,128,1), init_filter=16, drop_rate=best_configuration[\"dr\"], up_sampling=best_configuration[\"us\"], \n",
    "                                regularization=reg, batch_norm=best_configuration[\"bn\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        UNet_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        UNet_results = UNet_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        val_loss, _ = UNet_model.evaluate(x_val, y_val, verbose=0)\n",
    "        print(f\"val_loss={val_loss} (reg={reg})\")\n",
    "        print(f\"val_loss={val_loss} (reg={reg})\\n\", file=f)\n",
    "\n",
    "        if val_loss < best_configuration[\"val_loss\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            print(\"*** best_configuration updated\\n\", file=f)\n",
    "            best_configuration[\"val_loss\"] = val_loss\n",
    "            best_configuration[\"loss\"] = UNet_results.history[\"loss\"]\n",
    "            best_configuration[\"reg\"] = reg\n",
    "\n",
    "            UNet_model.save(\"UNet_model.h5\")\n",
    "    \n",
    "    for dr in drop_rate:\n",
    "        UNet_model = Unet_Model(input_shape=(128,128,1), init_filter=16, drop_rate=dr, up_sampling=best_configuration[\"us\"], \n",
    "                                regularization=best_configuration[\"reg\"], batch_norm=best_configuration[\"bn\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        UNet_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        UNet_results = UNet_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        val_loss, _ = UNet_model.evaluate(x_val, y_val, verbose=0)\n",
    "        print(f\"val_loss={val_loss} (dr={dr})\")\n",
    "        print(f\"val_loss={val_loss} (dr={dr})\\n\", file=f)\n",
    "\n",
    "        if val_loss < best_configuration[\"val_loss\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            print(\"*** best_configuration updated\\n\", file=f)\n",
    "            best_configuration[\"val_loss\"] = val_loss\n",
    "            best_configuration[\"loss\"] = UNet_results.history[\"loss\"]\n",
    "            best_configuration[\"dr\"] = dr\n",
    "\n",
    "            UNet_model.save(\"UNet_model.h5\")\n",
    "\n",
    "    print(f\"Test dropout rate - best configuration: {best_configuration}\\n\", file=f)\n",
    "\n",
    "    for us in up_sample:\n",
    "        UNet_model = Unet_Model(input_shape=(128,128,1), init_filter=16, drop_rate=best_configuration[\"dr\"], up_sampling=us, \n",
    "                                regularization=best_configuration[\"reg\"], batch_norm=best_configuration[\"bn\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        UNet_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        UNet_results = UNet_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        val_loss, _ = UNet_model.evaluate(x_val, y_val, verbose=0)\n",
    "        print(f\"val_loss={val_loss} (us={us})\")\n",
    "        print(f\"val_loss={val_loss} (us={us})\\n\", file=f)\n",
    "\n",
    "        if val_loss < best_configuration[\"val_loss\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            print(\"*** best_configuration updated\\n\", file=f)\n",
    "            best_configuration[\"val_loss\"] = val_loss\n",
    "            best_configuration[\"loss\"] = UNet_results.history[\"loss\"]\n",
    "            best_configuration[\"us\"] = us\n",
    "\n",
    "            UNet_model.save(\"UNet_model.h5\")\n",
    "\n",
    "    print(f\"Test upsampling - best configuration: {best_configuration}\\n\", file=f)\n",
    "\n",
    "    for bn in batch_norm:\n",
    "        UNet_model = Unet_Model(input_shape=(128,128,1), init_filter=16, drop_rate=best_configuration[\"dr\"], up_sampling=best_configuration[\"us\"], \n",
    "                                regularization=best_configuration[\"reg\"], batch_norm=bn)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        UNet_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        UNet_results = UNet_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        val_loss, _ = UNet_model.evaluate(x_val, y_val, verbose=0)\n",
    "        print(f\"val_loss={val_loss} (bn={bn})\")\n",
    "        print(f\"val_loss={val_loss} (bn={bn})\\n\", file=f)\n",
    "\n",
    "        if val_loss < best_configuration[\"val_loss\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            best_configuration[\"val_loss\"] = val_loss\n",
    "            best_configuration[\"loss\"] = UNet_results.history[\"loss\"]\n",
    "            best_configuration[\"bn\"] = bn\n",
    "\n",
    "            UNet_model.save(\"UNet_model.h5\")\n",
    "\n",
    "    print(f\"Test batch normalization - best configuration: {best_configuration}\\n\", file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730087752.907516   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.211656   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.211737   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.214367   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.214400   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.214412   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.441924   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730087753.441972   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-28 10:55:53.441982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730087753.442016   73201 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-28 10:55:53.447109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730087757.236271   73467 service.cc:146] XLA service 0x7f00b0002520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730087757.236313   73467 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-28 10:55:57.325690: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-28 10:55:57.773924: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "I0000 00:00:1730087771.106869   73467 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=0.19707901775836945 (lr=0.0001)\n",
      "*** best_configuration updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss=0.14779502153396606 (lr=0.001)\n",
      "*** best_configuration updated\n",
      "val_loss=1.1295499801635742 (lr=0.01)\n",
      "val_loss=1.1295499801635742 (lr=0.1)\n"
     ]
    }
   ],
   "source": [
    "with open(\"unet_tuning_output.txt\", \"a\") as f:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Run at {current_time}\\n\", file=f)\n",
    "    \n",
    "    # Test learning rate\n",
    "    for lr in learning_rate:\n",
    "        UNet_model = Unet_Model(input_shape=(128,128,1), init_filter=16, drop_rate=best_configuration[\"dr\"], up_sampling=best_configuration[\"us\"], \n",
    "                                regularization=best_configuration[\"reg\"], batch_norm=best_configuration[\"bn\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        UNet_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        UNet_results = UNet_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        val_loss, _ = UNet_model.evaluate(x_val, y_val, verbose=0)\n",
    "        print(f\"val_loss={val_loss} (lr={lr})\")\n",
    "        print(f\"val_loss={val_loss} (lr={lr})\\n\", file=f)\n",
    "\n",
    "        if val_loss < best_configuration[\"val_loss\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            print(\"*** best_configuration updated\\n\", file=f)\n",
    "            best_configuration[\"val_loss\"] = val_loss\n",
    "            best_configuration[\"loss\"] = UNet_results.history[\"loss\"]\n",
    "            best_configuration[\"lr\"] = lr\n",
    "\n",
    "            UNet_model.save(\"UNet_model.h5\")\n",
    "\n",
    "    print(f\"Test learning rate - best configuration: {best_configuration}\\n\", file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    x[x==\"normal\"] = 0\n",
    "    x[x==\"benign\"] = 1\n",
    "    x[x==\"malignant\"] = 2\n",
    "    x = x.astype(int)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(x):\n",
    "    x = encode(x)\n",
    "    x_onehot = np.zeros((x.size, x.max()+1))\n",
    "    x_onehot[np.arange(x.size),x] = 1\n",
    "\n",
    "    return x_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_onehot = onehot_encode(z_train)\n",
    "z_val_onehot = onehot_encode(z_val)\n",
    "z_test_onehot = onehot_encode(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tuning\n",
    "\n",
    "# Num Layer\n",
    "number_layers = [3, 4, 5]\n",
    "\n",
    "# Num Units\n",
    "number_units = [16, 32, 64, 128, 256]\n",
    "\n",
    "# Dropout Rates\n",
    "drop_rates = [0.05, 0.1, 0.2, 0.3]\n",
    "\n",
    "# Learning Rates\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "best_configuration = dict(\n",
    "    val_acc=float(0), \n",
    "    num_layers=number_layers[0], \n",
    "    num_units=number_units[2], \n",
    "    dr=drop_rates[0], \n",
    "    lr=learning_rates[2], \n",
    "    epoch_num=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730099686.144836   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.452155   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.452196   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.454788   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.454827   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.454840   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.581944   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730099686.582065   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-28 14:14:46.582080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730099686.582125   99549 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-28 14:14:46.582716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730099690.418864   99655 service.cc:146] XLA service 0x7ff58801efc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730099690.418900   99655 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-28 14:14:50.443645: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-28 14:14:50.562643: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730099694.983874   99655 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc=0.7820512652397156 (num_layers=3)\n",
      "*** best_configuration updated\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "val_acc=0.7051281929016113 (num_layers=4)\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "val_acc=0.7820512652397156 (num_layers=5)\n"
     ]
    }
   ],
   "source": [
    "with open(\"cnn_tuning_output.txt\", \"a\") as f:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Run at {current_time}\\n\", file=f)\n",
    "\n",
    "    UNet_model = tf.keras.models.load_model(\"models/UNet_model.h5\")\n",
    "\n",
    "    for number_layer in number_layers:\n",
    "        CNN_model = CNN_Model(input_shape=(128,128,1), num_layer=number_layer, num_unit=best_configuration[\"num_units\"], drop_rate=best_configuration[\"dr\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        CNN_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        CNN_results = CNN_model.fit([x_train, UNet_model.predict(x_train)], z_train_onehot, validation_data=([x_val, UNet_model.predict(x_val)], z_val_onehot), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        _, val_acc = CNN_model.evaluate([x_val, UNet_model.predict(x_val)], z_val_onehot, verbose=0)\n",
    "        print(f\"val_acc={val_acc} (num_layers={number_layer})\")\n",
    "\n",
    "        if val_acc > best_configuration[\"val_acc\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            best_configuration[\"val_acc\"] = val_acc\n",
    "            best_configuration[\"loss\"] = CNN_results.history[\"loss\"]\n",
    "            best_configuration[\"val_loss\"] = CNN_results.history[\"val_loss\"]\n",
    "            best_configuration[\"num_layers\"] = number_layer\n",
    "\n",
    "            CNN_model.save(\"CNN_model.h5\")\n",
    "\n",
    "    print(f\"Test number of layers - best configuration: {best_configuration}\\n\", file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n"
     ]
    }
   ],
   "source": [
    "with open(\"cnn_tuning_output.txt\", \"a\") as f:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Run at {current_time}\\n\", file=f)\n",
    "\n",
    "    UNet_model = tf.keras.models.load_model(\"models/UNet_model.h5\")\n",
    "    # Test number of units\n",
    "    for number_unit in number_units:\n",
    "        CNN_model = CNN_Model(input_shape=(128,128,1), num_layer=best_configuration[\"num_layers\"], num_unit=number_unit, drop_rate=best_configuration[\"dr\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        CNN_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        CNN_results = CNN_model.fit([x_train, UNet_model.predict(x_train)], z_train_onehot, validation_data=([x_val, UNet_model.predict(x_val)], z_val_onehot), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        _, val_acc = CNN_model.evaluate([x_val, UNet_model.predict(x_val)], z_val_onehot, verbose=0)\n",
    "        print(f\"val_acc={val_acc} (num_units={number_unit})\")\n",
    "\n",
    "        if val_acc > best_configuration[\"val_acc\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            best_configuration[\"val_acc\"] = val_acc\n",
    "            best_configuration[\"loss\"] = CNN_results.history[\"loss\"]\n",
    "            best_configuration[\"val_loss\"] = CNN_results.history[\"val_loss\"]\n",
    "            best_configuration[\"num_units\"] = number_unit\n",
    "\n",
    "            CNN_model.save(\"CNN_model.h5\")\n",
    "\n",
    "    print(f\"Test number of units - best configuration: {best_configuration}\\n\", file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"cnn_tuning_output.txt\", \"a\") as f:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Run at {current_time}\\n\", file=f)\n",
    "\n",
    "    UNet_model = tf.keras.models.load_model(\"models/UNet_model.h5\")\n",
    "\n",
    "    # Test dropout rate\n",
    "    for dr in drop_rates:\n",
    "        CNN_model = CNN_Model(input_shape=(128,128,1), num_layer=best_configuration[\"num_layers\"], num_unit=best_configuration[\"num_units\"], drop_rate=dr)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=best_configuration[\"lr\"])\n",
    "        CNN_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        CNN_results = CNN_model.fit([x_train, UNet_model.predict(x_train)], z_train_onehot, validation_data=([x_val, UNet_model.predict(x_val)], z_val_onehot), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        _, val_acc = CNN_model.evaluate([x_val, UNet_model.predict(x_val)], z_val_onehot, verbose=0)\n",
    "        print(f\"val_acc={val_acc} (dr={dr})\")\n",
    "\n",
    "        if val_acc > best_configuration[\"val_acc\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            best_configuration[\"val_acc\"] = val_acc\n",
    "            best_configuration[\"loss\"] = CNN_results.history[\"loss\"]\n",
    "            best_configuration[\"val_loss\"] = CNN_results.history[\"val_loss\"]\n",
    "            best_configuration[\"dr\"] = dr\n",
    "\n",
    "            CNN_model.save(\"CNN_model.h5\")\n",
    "\n",
    "    print(f\"Test dropout rate - best configuration: {best_configuration}\\n\", file=f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cnn_tuning_output.txt\", \"a\") as f:\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"Run at {current_time}\\n\", file=f)\n",
    "\n",
    "    UNet_model = tf.keras.models.load_model(\"models/UNet_model.h5\")\n",
    "\n",
    "    # Test learning rate\n",
    "    for lr in learning_rates:\n",
    "        CNN_model = CNN_Model(input_shape=(128,128,1), num_layer=best_configuration[\"num_layers\"], num_unit=best_configuration[\"num_units\"], drop_rate=best_configuration[\"dr\"])\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "        CNN_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        CNN_results = CNN_model.fit([x_train, UNet_model.predict(x_train)], z_train_onehot, validation_data=([x_val, UNet_model.predict(x_val)], z_val_onehot), epochs=best_configuration[\"epoch_num\"], verbose=0)\n",
    "        _, val_acc = CNN_model.evaluate([x_val, UNet_model.predict(x_val)], z_val_onehot, verbose=0)\n",
    "        print(f\"val_acc={val_acc} (lr={lr})\")\n",
    "\n",
    "        if val_acc > best_configuration[\"val_acc\"]:\n",
    "            print(\"*** best_configuration updated\")\n",
    "            best_configuration[\"val_acc\"] = val_acc\n",
    "            best_configuration[\"loss\"] = CNN_results.history[\"loss\"]\n",
    "            best_configuration[\"val_loss\"] = CNN_results.history[\"val_loss\"]\n",
    "            best_configuration[\"lr\"] = lr\n",
    "\n",
    "            CNN_model.save(\"CNN_model.h5\")\n",
    "\n",
    "    print(f\"Test learning rate - best configuration: {best_configuration}\\n\", file=f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
